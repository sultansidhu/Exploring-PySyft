{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19bd1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3511488",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4387d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(\n",
    "            28*28, # input size of each MNIST image\n",
    "            512\n",
    "        )\n",
    "        self.output = nn.Linear(\n",
    "            512, \n",
    "            10 # 10 output classes\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4131bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ec3840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # negative log likelihood loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bea3731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The running loss is 2.0905602995012362\n",
      "The running loss is 1.4563867526013714\n",
      "The running loss is 0.9612063618102816\n",
      "The running loss is 0.7290523802039466\n",
      "The running loss is 0.6098393502075281\n",
      "The running loss is 0.5386890012191049\n",
      "The running loss is 0.4913935706273579\n",
      "The running loss is 0.4579610631251132\n",
      "The running loss is 0.4331237437215441\n",
      "The running loss is 0.4142616478396631\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1) # flattening\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images) # prediction\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() \n",
    "        running_loss += loss.item()\n",
    "    print(f\"The running loss is {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dcc24e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd5a3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = img[0].view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "332c9252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-11.3807,  -0.0222,  -5.3195,  -4.9635,  -8.9189,  -6.2036,  -6.9094,\n",
      "          -6.1706,  -5.5182,  -7.0949]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # no computation graph needed here\n",
    "    logprobs = model(im)\n",
    "print(logprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31f7e3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.exp(logprobs)\n",
    "prediction = torch.argmax(probs)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56af1af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f1ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
